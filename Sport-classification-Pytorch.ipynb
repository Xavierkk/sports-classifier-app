{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b46e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Tell PyTorch to treat the 5060 Ti as a 40-series (Ada) if it's confused.\n",
    "# This ensures 100% compatibility without performance loss.\n",
    "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"9.0\" \n",
    "\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Is CUDA available? {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    # This should now work without crashing your training loop\n",
    "    print(\"Success! Your 5060 Ti is ready for Sports Classification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f940834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05350493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save Label Encoder and Migrate Data to PostgreSQL\n",
    "# # Used only once to set up the database for the API\n",
    "\n",
    "# from sqlalchemy import create_engine\n",
    "# import joblib\n",
    "\n",
    "# # 1. SAVE YOUR LABEL MAPPING\n",
    "# # Industrial requirement: The API needs to know that 0='Archery', etc.\n",
    "# joblib.dump(le, 'label_encoder.joblib')\n",
    "# print(\"Label Encoder saved as 'label_encoder.joblib'\")\n",
    "\n",
    "# # 2. CREATE THE SQL CONNECTION\n",
    "# # Format: postgresql://username:password@localhost:5432/database_name\n",
    "# # Replace 'your_password' with the password you set in Stack Builder\n",
    "# engine = create_engine('postgresql://postgres:X1t0IOzgT0mhtWLt47Zqc8s8XHbXWQ1F@localhost:5432/sports_db')\n",
    "\n",
    "# # 3. MIGRATE DATA TO POSTGRESQL\n",
    "# # This automatically creates the tables and columns in 'sports_db'\n",
    "# try:\n",
    "#     df_train.to_sql('train_metadata', engine, if_exists='replace', index=False)\n",
    "#     df_test.to_sql('test_metadata', engine, if_exists='replace', index=False)\n",
    "#     df_val.to_sql('val_metadata', engine, if_exists='replace', index=False)\n",
    "#     print(\"Migration Successful: 3 tables created in PostgreSQL.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Migration Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b62349",
   "metadata": {},
   "source": [
    "# Data Loading from PostSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49df5697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata from PostgreSQL...\n",
      "Production Load Successful. Train shape: (13492, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import joblib\n",
    "from PIL import Image\n",
    "\n",
    "# --- 1. INDUSTRIAL DATABASE CONNECTION ---\n",
    "# Use the same port and password you used for migration\n",
    "engine = create_engine('postgresql://postgres:X1t0IOzgT0mhtWLt47Zqc8s8XHbXWQ1F@localhost:5432/sports_db')\n",
    "\n",
    "# Load the encoder you saved during the migration step\n",
    "# This ensures 'le' is available for saving later!\n",
    "le = joblib.load('label_encoder.joblib')\n",
    "\n",
    "def load_data_from_production():\n",
    "    print(\"Fetching metadata from PostgreSQL...\")\n",
    "    \n",
    "    # Query the tables you created during migration\n",
    "    df_train = pd.read_sql_query(\"SELECT * FROM train_metadata\", engine)\n",
    "    df_val = pd.read_sql_query(\"SELECT * FROM val_metadata\", engine)\n",
    "    df_test = pd.read_sql_query(\"SELECT * FROM test_metadata\", engine)\n",
    "    \n",
    "    # Re-establish the full path for the local images\n",
    "    base_path = 'dataset/'\n",
    "    for df in [df_train, df_val, df_test]:\n",
    "        df['full_path'] = base_path + df['filepaths']\n",
    "        \n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "# Load variables following your original naming convention\n",
    "df_train, df_val, df_test = load_data_from_production()\n",
    "\n",
    "print(f\"Production Load Successful. Train shape: {df_train.shape}\")\n",
    "\n",
    "# --- 2. DATASET & DATALOADERS ---\n",
    "class SportsDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe # This is the data from SQL\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['full_path']\n",
    "        image = Image.open(img_path).convert('RGB') # Opens the file\n",
    "        label = int(self.df.iloc[idx]['labels'])    # Gets the sport ID\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "train_ds = SportsDataset(df_train, transform=transform)\n",
    "val_ds = SportsDataset(df_val, transform=transform)\n",
    "test_ds = SportsDataset(df_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Preparation and Preprocessing\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Load and Setup Paths\n",
    "# df = pd.read_csv('dataset/sports.csv')\n",
    "# base_path = 'dataset/'\n",
    "# df['full_path'] = base_path + df['filepaths']\n",
    "\n",
    "# # Encode labels\n",
    "# le = LabelEncoder()\n",
    "# df['labels'] = le.fit_transform(df['labels'])\n",
    "\n",
    "# # Split data based on the 'data set' column\n",
    "# df_train = df[df['data set'] == 'train'].copy()\n",
    "# df_test = df[df['data set'] == 'test'].copy()\n",
    "# df_val = df[df['data set'] == 'valid'].copy()\n",
    "\n",
    "# print(f\"Train shape: {df_train.shape}\")\n",
    "\n",
    "# # Filter out any non-image files from your dataframes\n",
    "# valid_extensions = ('.jpg', '.jpeg', '.png', '.webp')\n",
    "\n",
    "# # Correctly use the .str accessor for both methods\n",
    "# df_train = df_train[df_train['full_path'].str.lower().str.endswith(valid_extensions)]\n",
    "# df_val = df_val[df_val['full_path'].str.lower().str.endswith(valid_extensions)]\n",
    "# df_test = df_test[df_test['full_path'].str.lower().str.endswith(valid_extensions)]\n",
    "\n",
    "# print(f\"Cleaned Train shape: {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "\n",
    "# class SportsDataset(Dataset):\n",
    "#     def __init__(self, dataframe, transform=None):\n",
    "#         self.df = dataframe\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = self.df.iloc[idx]['full_path']\n",
    "#         # Load image on demand\n",
    "#         image = Image.open(img_path).convert('RGB')\n",
    "#         label = int(self.df.iloc[idx]['labels'])\n",
    "        \n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "            \n",
    "#         return image, label\n",
    "\n",
    "# # Image Transforms: Resize and Normalize (0 to 1)\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(), \n",
    "# ])\n",
    "\n",
    "# # Create Dataset objects\n",
    "# train_ds = SportsDataset(df_train, transform=transform)\n",
    "# val_ds = SportsDataset(df_val, transform=transform)\n",
    "# test_ds = SportsDataset(df_test, transform=transform)\n",
    "\n",
    "# # Create DataLoaders\n",
    "# train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "# test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9dfd6b",
   "metadata": {},
   "source": [
    "# CNN Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.amp import autocast, GradScaler\n",
    "# import copy\n",
    "\n",
    "# # --- 1. MODEL DEFINITION ---\n",
    "# class SportsCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SportsCNN, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "            \n",
    "#             nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "            \n",
    "#             nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "            \n",
    "#             nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2)\n",
    "#         )\n",
    "        \n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(256 * 14 * 14, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 100) # Raw logits for CrossEntropyLoss\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "# # --- 2. STRICT GPU SETUP ---\n",
    "# if not torch.cuda.is_available():\n",
    "#     raise RuntimeError(\"ðŸš¨ CUDA-capable GPU not found! Training aborted.\")\n",
    "\n",
    "# device = torch.device(\"cuda\")\n",
    "# print(f\"Confirmed: Training on {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# # Optimization for Blackwell/Core Ultra architecture\n",
    "# torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# # --- 3. INITIALIZATION ---\n",
    "# model = SportsCNN().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# scaler = GradScaler()\n",
    "\n",
    "# # Early Stopping Configuration\n",
    "# patience = 15\n",
    "# min_delta = 1e-5\n",
    "# best_val_loss = float('inf')\n",
    "# counter = 0\n",
    "# best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# # --- 4. TRAINING LOOP ---\n",
    "# print(f\"\\n{'Epoch':<8} | {'Loss':<8} | {'Acc':<8} | {'Val Loss':<8} | {'Val Acc':<8}\")\n",
    "# print(\"-\" * 55)\n",
    "\n",
    "# for epoch in range(1, 1001):\n",
    "#     # --- TRAINING PHASE ---\n",
    "#     model.train()\n",
    "#     train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "    \n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        \n",
    "#         optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "#         # Use bfloat16 for Blackwell performance\n",
    "#         with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "        \n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "\n",
    "#         # Metrics calculation\n",
    "#         train_loss += loss.item() * images.size(0)\n",
    "#         _, predicted = outputs.max(1)\n",
    "#         train_total += labels.size(0)\n",
    "#         train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#     avg_train_loss = train_loss / train_total\n",
    "#     avg_train_acc = 100. * train_correct / train_total\n",
    "\n",
    "#     # --- VALIDATION PHASE ---\n",
    "#     model.eval()\n",
    "#     val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in val_loader:\n",
    "#             images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "#             with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#                 outputs = model(images)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "                \n",
    "#                 val_loss += loss.item() * images.size(0)\n",
    "#                 _, predicted = outputs.max(1)\n",
    "#                 val_total += labels.size(0)\n",
    "#                 val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "#     avg_val_loss = val_loss / val_total\n",
    "#     avg_val_acc = 100. * val_correct / val_total\n",
    "    \n",
    "#     # Mimic Keras verbose output\n",
    "#     print(f\"{epoch:<8} | {avg_train_loss:<8.4f} | {avg_train_acc:<7.2f}% | {avg_val_loss:<8.4f} | {avg_val_acc:<7.2f}%\")\n",
    "\n",
    "#     # --- EARLY STOPPING LOGIC ---\n",
    "#     if avg_val_loss < (best_val_loss - min_delta):\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         best_model_weights = copy.deepcopy(model.state_dict())\n",
    "#         counter = 0\n",
    "#     else:\n",
    "#         counter += 1\n",
    "#         if counter >= patience:\n",
    "#             print(f\"\\nâœ… Early stopping triggered at epoch {epoch}. Restoring best weights.\")\n",
    "#             break\n",
    "\n",
    "# # Load the best weights back\n",
    "# model.load_state_dict(best_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae472de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 5. FINAL TEST EVALUATION ---\n",
    "# model.eval()\n",
    "# test_loss = 0.0\n",
    "# test_correct = 0\n",
    "# test_total = 0\n",
    "\n",
    "# print(\"\\n\" + \"=\"*55)\n",
    "# print(f\"{'Final Test Evaluation':^55}\")\n",
    "# print(\"=\"*55)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         # Move data to GPU\n",
    "#         images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        \n",
    "#         # Consistent bfloat16 inference for Blackwell\n",
    "#         with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "#             # Update metrics\n",
    "#             test_loss += loss.item() * images.size(0)\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             test_total += labels.size(0)\n",
    "#             test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "# # Final averages\n",
    "# final_test_loss = test_loss / test_total\n",
    "# final_test_acc = 100. * test_correct / test_total\n",
    "\n",
    "# print(f\"Test Loss     : {final_test_loss:.4f}\")\n",
    "# print(f\"Test Accuracy : {final_test_acc:.2f}%\")\n",
    "# print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c406156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CNN Version 2 \n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.amp import autocast, GradScaler\n",
    "# import copy\n",
    "\n",
    "# # --- 1. MODEL DEFINITION (VERSION 2) ---\n",
    "# class SportsCNN_V2(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SportsCNN_V2, self).__init__()\n",
    "        \n",
    "#         def conv_block(in_f, out_f, drop_rate):\n",
    "#             return nn.Sequential(\n",
    "#                 nn.Conv2d(in_f, out_f, kernel_size=3, padding=1),\n",
    "#                 nn.BatchNorm2d(out_f),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.MaxPool2d(2, 2),\n",
    "#                 nn.Dropout2d(drop_rate)\n",
    "#             )\n",
    "\n",
    "#         self.features = nn.Sequential(\n",
    "#             conv_block(3, 32, 0.25),\n",
    "#             conv_block(32, 64, 0.25),\n",
    "#             conv_block(64, 128, 0.3),\n",
    "#             conv_block(128, 256, 0.4)\n",
    "#         )\n",
    "        \n",
    "#         self.global_pool = nn.AdaptiveAvgPool2d(1) # GlobalAveragePooling2D\n",
    "        \n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(256, 512),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(512, 100)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.global_pool(x)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "# # --- 2. STRICT GPU SETUP ---\n",
    "# if not torch.cuda.is_available():\n",
    "#     raise RuntimeError(\"ðŸš¨ CUDA-capable GPU not found!\")\n",
    "\n",
    "# device = torch.device(\"cuda\")\n",
    "# print(f\"Confirmed: Training on {torch.cuda.get_device_name(0)}\")\n",
    "# torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# # --- 3. INITIALIZATION ---\n",
    "# model = SportsCNN_V2().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# scaler = GradScaler()\n",
    "\n",
    "# # Early Stopping Configuration\n",
    "# patience = 15\n",
    "# min_delta = 1e-5\n",
    "# best_val_loss = float('inf')\n",
    "# counter = 0\n",
    "# best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# # --- 4. TRAINING LOOP ---\n",
    "# print(f\"\\n{'Epoch':<8} | {'Loss':<8} | {'Acc':<8} | {'Val Loss':<8} | {'Val Acc':<8}\")\n",
    "# print(\"-\" * 55)\n",
    "\n",
    "# for epoch in range(1, 1001):\n",
    "#     model.train()\n",
    "#     train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "    \n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "#         optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "#         with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "        \n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "\n",
    "#         train_loss += loss.item() * images.size(0)\n",
    "#         _, predicted = outputs.max(1)\n",
    "#         train_total += labels.size(0)\n",
    "#         train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#     avg_train_loss = train_loss / train_total\n",
    "#     avg_train_acc = 100. * train_correct / train_total\n",
    "\n",
    "#     model.eval()\n",
    "#     val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in val_loader:\n",
    "#             images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "#             with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#                 outputs = model(images)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item() * images.size(0)\n",
    "#                 _, predicted = outputs.max(1)\n",
    "#                 val_total += labels.size(0)\n",
    "#                 val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "#     avg_val_loss = val_loss / val_total\n",
    "#     avg_val_acc = 100. * val_correct / val_total\n",
    "    \n",
    "#     print(f\"{epoch:<8} | {avg_train_loss:<8.4f} | {avg_train_acc:<7.2f}% | {avg_val_loss:<8.4f} | {avg_val_acc:<7.2f}%\")\n",
    "\n",
    "#     if avg_val_loss < (best_val_loss - min_delta):\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         best_model_weights = copy.deepcopy(model.state_dict())\n",
    "#         counter = 0\n",
    "#     else:\n",
    "#         counter += 1\n",
    "#         if counter >= patience:\n",
    "#             print(f\"\\nâœ… Early stopping at epoch {epoch}. Restoring best weights.\")\n",
    "#             break\n",
    "\n",
    "# model.load_state_dict(best_model_weights)\n",
    "\n",
    "# # --- 5. FINAL TEST EVALUATION ---\n",
    "# model.eval()\n",
    "# test_loss, test_correct, test_total = 0.0, 0, 0\n",
    "# print(\"\\n\" + \"=\"*55)\n",
    "# print(f\"{'Final Test Evaluation':^55}\")\n",
    "# print(\"=\"*55)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "#         with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item() * images.size(0)\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             test_total += labels.size(0)\n",
    "#             test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "# print(f\"Test Loss     : {test_loss/test_total:.4f}\")\n",
    "# print(f\"Test Accuracy : {100.*test_correct/test_total:.2f}%\")\n",
    "# print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c884998",
   "metadata": {},
   "source": [
    "# ResNET50 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2336a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import models\n",
    "# from torch.amp import autocast, GradScaler\n",
    "# import copy\n",
    "\n",
    "# # --- 1. MODEL DEFINITION ---\n",
    "# class SportsResNet(nn.Module):\n",
    "#     def __init__(self, num_classes=100):\n",
    "#         super(SportsResNet, self).__init__()\n",
    "#         # Weights='imagenet', include_top=False\n",
    "#         self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "#         # Identity removes the original FC layer (include_top=False)\n",
    "#         self.base_model.fc = nn.Identity() \n",
    "        \n",
    "#         # AdaptiveAvgPool2d(1) is the direct equivalent of GlobalAveragePooling2D\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(2048, 512), # ResNet50 output is 2048 channels\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),      # Dropout(0.5)\n",
    "#             nn.Linear(512, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.base_model.conv1(x)\n",
    "#         x = self.base_model.bn1(x)\n",
    "#         x = self.base_model.relu(x)\n",
    "#         x = self.base_model.maxpool(x)\n",
    "\n",
    "#         x = self.base_model.layer1(x)\n",
    "#         x = self.base_model.layer2(x)\n",
    "#         x = self.base_model.layer3(x)\n",
    "#         x = self.base_model.layer4(x) # This is 'conv5' in Keras\n",
    "\n",
    "#         x = self.avgpool(x)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "# # --- 2. SETUP ---\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = SportsResNet(num_classes=100).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# scaler = GradScaler()\n",
    "\n",
    "# # --- STAGE 1: FREEZE ALL BASE LAYERS ---\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Optimizer focuses only on the new classifier (same as Keras stage 1)\n",
    "# optimizer_v1 = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "# # Helper function remains the same as your previous structure\n",
    "# def train_model(model, optimizer, epochs, stage_name):\n",
    "#     best_val_loss = float('inf')\n",
    "#     patience = 15\n",
    "#     min_delta = 1e-5\n",
    "#     counter = 0\n",
    "#     best_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "#     print(f\"\\n--- Starting {stage_name} ---\")\n",
    "#     print(f\"{'Epoch':<8} | {'Loss':<8} | {'Acc':<8} | {'Val Loss':<8} | {'Val Acc':<8}\")\n",
    "#     print(\"-\" * 55)\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         model.train()\n",
    "#         t_loss, t_corr, t_total = 0, 0, 0\n",
    "#         for imgs, lbls in train_loader:\n",
    "#             imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "#             optimizer.zero_grad(set_to_none=True)\n",
    "#             with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#                 outputs = model(imgs)\n",
    "#                 loss = criterion(outputs, lbls)\n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "            \n",
    "#             t_loss += loss.item() * imgs.size(0)\n",
    "#             _, pred = outputs.max(1)\n",
    "#             t_total += lbls.size(0)\n",
    "#             t_corr += pred.eq(lbls).sum().item()\n",
    "\n",
    "#         model.eval()\n",
    "#         v_loss, v_corr, v_total = 0, 0, 0\n",
    "#         with torch.no_grad():\n",
    "#             for imgs, lbls in val_loader:\n",
    "#                 imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "#                 with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#                     outputs = model(imgs)\n",
    "#                     loss = criterion(outputs, lbls)\n",
    "#                 v_loss += loss.item() * imgs.size(0)\n",
    "#                 _, pred = outputs.max(1)\n",
    "#                 v_total += lbls.size(0)\n",
    "#                 v_corr += pred.eq(lbls).sum().item()\n",
    "\n",
    "#         avg_v_loss = v_loss / v_total\n",
    "#         print(f\"{epoch:<8} | {t_loss/t_total:<8.4f} | {100.*t_corr/t_total:<7.2f}% | {avg_v_loss:<8.4f} | {100.*v_corr/v_total:<7.2f}%\")\n",
    "\n",
    "#         if avg_v_loss < (best_val_loss - min_delta):\n",
    "#             best_val_loss = avg_v_loss\n",
    "#             best_weights = copy.deepcopy(model.state_dict())\n",
    "#             counter = 0\n",
    "#         else:\n",
    "#             counter += 1\n",
    "#             if counter >= patience:\n",
    "#                 print(f\"Early Stopping triggered.\")\n",
    "#                 break\n",
    "    \n",
    "#     model.load_state_dict(best_weights)\n",
    "#     return model\n",
    "\n",
    "# # Run Stage 1\n",
    "# model = train_model(model, optimizer_v1, epochs=1000, stage_name=\"Feature Extraction\")\n",
    "\n",
    "# # --- STAGE 2: UNFREEZE 'conv5' (layer4 in PyTorch) ---\n",
    "# # This matches your 'if conv5 in layer.name' logic\n",
    "# for param in model.base_model.layer4.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# # Re-initialize optimizer (Keras .compile equivalent)\n",
    "# # In your Keras code, you used 'adam' again without changing LR, so we stay at 0.001\n",
    "# optimizer_v2 = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# # Run Stage 2\n",
    "# model = train_model(model, optimizer_v2, epochs=1000, stage_name=\"Fine-Tuning (Layer 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9676e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "import joblib\n",
    "\n",
    "# RE-DECLARE YOUR CLASS EXACTLY AS IN TRAINING\n",
    "class SportsResNet(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(SportsResNet, self).__init__()\n",
    "        self.base_model = models.resnet50()\n",
    "        self.base_model.fc = nn.Identity() \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.conv1(x)\n",
    "        x = self.base_model.bn1(x)\n",
    "        x = self.base_model.relu(x)\n",
    "        x = self.base_model.maxpool(x)\n",
    "        x = self.base_model.layer1(x)\n",
    "        x = self.base_model.layer2(x)\n",
    "        x = self.base_model.layer3(x)\n",
    "        x = self.base_model.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# GLOBAL LOAD (Only happens once when server starts)\n",
    "device = torch.device(\"cpu\") # Deployment is usually CPU unless high volume\n",
    "model = SportsResNet(num_classes=100)\n",
    "model.load_state_dict(torch.load(\"resnet50_sports.pth\", map_location=device))\n",
    "model.eval()\n",
    "le = joblib.load(\"label_encoder.joblib\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    data = await file.read()\n",
    "    image = Image.open(io.BytesIO(data)).convert('RGB')\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "    \n",
    "    sport_name = le.inverse_transform([pred.item()])[0]\n",
    "    return {\"sport\": sport_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. TEST EVALUATION ---\n",
    "model.eval()  # Set model to evaluation mode\n",
    "test_loss, test_corr, test_total = 0, 0, 0\n",
    "\n",
    "print(f\"\\n--- Evaluating on Test Data ---\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, lbls in test_loader:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        \n",
    "        # Use autocast if you used it during training for consistency\n",
    "        with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, lbls)\n",
    "        \n",
    "        test_loss += loss.item() * imgs.size(0)\n",
    "        _, pred = outputs.max(1)\n",
    "        test_total += lbls.size(0)\n",
    "        test_corr += pred.eq(lbls).sum().item()\n",
    "\n",
    "final_test_loss = test_loss / test_total\n",
    "final_test_acc = test_corr / test_total\n",
    "\n",
    "print(f\"Test Loss: {final_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {final_test_acc:.4f}\")\n",
    "print(f\"Test Accuracy Percentage: {100.*final_test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ad56d",
   "metadata": {},
   "source": [
    "# Visualization of the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bca4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def visualize_random_predictions(model, dataset, classes, num_images=5):\n",
    "    model.eval()\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Pick 5 random indices from the dataset\n",
    "    random_indices = random.sample(range(len(dataset)), num_images)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(random_indices):\n",
    "            # Get image and label from dataset\n",
    "            img_tensor, lbl_idx = dataset[idx]\n",
    "            \n",
    "            # Add batch dimension and move to device\n",
    "            img_input = img_tensor.unsqueeze(0).to(device)\n",
    "            \n",
    "            # Predict\n",
    "            outputs = model(img_input)\n",
    "            _, pred_idx = torch.max(outputs, 1)\n",
    "            \n",
    "            # Convert to numpy for plotting\n",
    "            img_vis = img_tensor.numpy().transpose((1, 2, 0))\n",
    "            img_vis = np.clip(img_vis, 0, 1)\n",
    "\n",
    "            # Map indices to names using your 'le.classes_' (passed as 'classes')\n",
    "            pred_name = classes[pred_idx.item()]\n",
    "            actual_name = classes[lbl_idx]\n",
    "\n",
    "            ax = plt.subplot(1, num_images, i + 1)\n",
    "            ax.axis('off')\n",
    "            color = 'green' if pred_idx.item() == lbl_idx else 'red'\n",
    "            ax.set_title(f\"Pred: {pred_name}\\nActual: {actual_name}\", color=color, fontsize=10)\n",
    "            plt.imshow(img_vis)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Execute using your variables\n",
    "visualize_random_predictions(model, test_ds, le.classes_, num_images=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
